{"ast":null,"code":"var _jsxFileName = \"/Users/shubhamkapoor/gather-video-chat/server/client/src/Model.js\",\n    _s = $RefreshSig$();\n\nimport React, { useRef } from 'react';\nimport * as tf from '@tensorflow/tfjs';\nimport * as handpose from '@tensorflow-models/handpose';\nimport Webcam from 'react-webcam';\nimport './Model.css';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nfunction Model(props) {\n  _s();\n\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n\n  const drawHand = (predictions, ctx) => {\n    if (predictions.length > 0) {\n      predictions.forEach(prediction => {\n        const landmarks = prediction.landmarks;\n\n        for (let i = 0; i < landmarks.length; i++) {\n          const x = landmarks[i][0];\n          const y = landmarks[i][1];\n          ctx.beginPath();\n          ctx.arc(x, y, 5, 0, 3 * Math.PI);\n          ctx.fillStyle = \"indigo\";\n          ctx.fill();\n        }\n      });\n    }\n  };\n\n  const runHandpose = async () => {\n    const net = await handpose.load();\n    setInterval(() => {\n      detect(net);\n    }, 100);\n  };\n\n  const detect = async net => {\n    if (typeof webcamRef.current !== \"undefined\" && webcamRef.current !== null && webcamRef.current.video.readyState === 4) {\n      const video = webcamRef.current.video;\n      const videoWidth = webcamRef.current.video.videoWidth;\n      const videoHeight = webcamRef.current.video.videoHeight;\n      webcamRef.current.video.width = videoWidth;\n      webcamRef.current.video.height = videoHeight;\n      canvasRef.current.width = videoWidth;\n      canvasRef.current.height = videoHeight;\n      const hand = await net.estimateHands(video);\n      const ctx = canvasRef.current.getContext(\"2d\");\n      drawHand(hand, ctx);\n    }\n  };\n\n  runHandpose();\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"model\",\n    children: [/*#__PURE__*/_jsxDEV(Webcam, {\n      ref: webcamRef,\n      style: {\n        width: \"100%\",\n        height: \"100%\"\n      }\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 62,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"canvas\", {\n      ref: canvasRef,\n      style: {\n        marginLeft: \"auto\",\n        marginRight: \"auto\",\n        left: 0,\n        right: 0,\n        textAlign: \"center\",\n        zindex: 9,\n        width: 640,\n        height: 480\n      }\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 69,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 61,\n    columnNumber: 3\n  }, this);\n}\n\n_s(Model, \"AwQWgsmsPhWgADiRou0jnDEtoH4=\");\n\n_c = Model;\nexport default Model;\n\nvar _c;\n\n$RefreshReg$(_c, \"Model\");","map":{"version":3,"sources":["/Users/shubhamkapoor/gather-video-chat/server/client/src/Model.js"],"names":["React","useRef","tf","handpose","Webcam","Model","props","webcamRef","canvasRef","drawHand","predictions","ctx","length","forEach","prediction","landmarks","i","x","y","beginPath","arc","Math","PI","fillStyle","fill","runHandpose","net","load","setInterval","detect","current","video","readyState","videoWidth","videoHeight","width","height","hand","estimateHands","getContext","marginLeft","marginRight","left","right","textAlign","zindex"],"mappings":";;;AAAA,OAAOA,KAAP,IAAgBC,MAAhB,QAA8B,OAA9B;AACA,OAAO,KAAKC,EAAZ,MAAoB,kBAApB;AACA,OAAO,KAAKC,QAAZ,MAA0B,6BAA1B;AACA,OAAOC,MAAP,MAAmB,cAAnB;AACA,OAAO,aAAP;;;AAEA,SAASC,KAAT,CAAeC,KAAf,EAAsB;AAAA;;AACrB,QAAMC,SAAS,GAAGN,MAAM,CAAC,IAAD,CAAxB;AACA,QAAMO,SAAS,GAAGP,MAAM,CAAC,IAAD,CAAxB;;AAEA,QAAMQ,QAAQ,GAAG,CAACC,WAAD,EAAcC,GAAd,KAAsB;AACtC,QAAID,WAAW,CAACE,MAAZ,GAAqB,CAAzB,EAA4B;AAC3BF,MAAAA,WAAW,CAACG,OAAZ,CAAoBC,UAAU,IAAI;AACjC,cAAMC,SAAS,GAAGD,UAAU,CAACC,SAA7B;;AACA,aAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGD,SAAS,CAACH,MAA9B,EAAsCI,CAAC,EAAvC,EAA4C;AAC3C,gBAAMC,CAAC,GAAGF,SAAS,CAACC,CAAD,CAAT,CAAa,CAAb,CAAV;AACA,gBAAME,CAAC,GAAGH,SAAS,CAACC,CAAD,CAAT,CAAa,CAAb,CAAV;AAEAL,UAAAA,GAAG,CAACQ,SAAJ;AACAR,UAAAA,GAAG,CAACS,GAAJ,CAAQH,CAAR,EAAWC,CAAX,EAAc,CAAd,EAAiB,CAAjB,EAAoB,IAAIG,IAAI,CAACC,EAA7B;AACAX,UAAAA,GAAG,CAACY,SAAJ,GAAgB,QAAhB;AACAZ,UAAAA,GAAG,CAACa,IAAJ;AACA;AACD,OAXD;AAYA;AACD,GAfD;;AAiBA,QAAMC,WAAW,GAAG,YAAY;AAC/B,UAAMC,GAAG,GAAG,MAAMvB,QAAQ,CAACwB,IAAT,EAAlB;AAEAC,IAAAA,WAAW,CAAC,MAAM;AACjBC,MAAAA,MAAM,CAACH,GAAD,CAAN;AACA,KAFU,EAER,GAFQ,CAAX;AAGA,GAND;;AAQC,QAAMG,MAAM,GAAG,MAAOH,GAAP,IAAe;AAC5B,QACE,OAAOnB,SAAS,CAACuB,OAAjB,KAA6B,WAA7B,IACAvB,SAAS,CAACuB,OAAV,KAAsB,IADtB,IAEAvB,SAAS,CAACuB,OAAV,CAAkBC,KAAlB,CAAwBC,UAAxB,KAAuC,CAHzC,EAIE;AACA,YAAMD,KAAK,GAAGxB,SAAS,CAACuB,OAAV,CAAkBC,KAAhC;AACA,YAAME,UAAU,GAAG1B,SAAS,CAACuB,OAAV,CAAkBC,KAAlB,CAAwBE,UAA3C;AACA,YAAMC,WAAW,GAAG3B,SAAS,CAACuB,OAAV,CAAkBC,KAAlB,CAAwBG,WAA5C;AAEA3B,MAAAA,SAAS,CAACuB,OAAV,CAAkBC,KAAlB,CAAwBI,KAAxB,GAAgCF,UAAhC;AACA1B,MAAAA,SAAS,CAACuB,OAAV,CAAkBC,KAAlB,CAAwBK,MAAxB,GAAiCF,WAAjC;AAEA1B,MAAAA,SAAS,CAACsB,OAAV,CAAkBK,KAAlB,GAA0BF,UAA1B;AACAzB,MAAAA,SAAS,CAACsB,OAAV,CAAkBM,MAAlB,GAA2BF,WAA3B;AAEA,YAAMG,IAAI,GAAG,MAAMX,GAAG,CAACY,aAAJ,CAAkBP,KAAlB,CAAnB;AACH,YAAMpB,GAAG,GAAGH,SAAS,CAACsB,OAAV,CAAkBS,UAAlB,CAA6B,IAA7B,CAAZ;AACA9B,MAAAA,QAAQ,CAAC4B,IAAD,EAAO1B,GAAP,CAAR;AACE;AACF,GApBD;;AAsBAc,EAAAA,WAAW;AAEZ,sBACC;AAAK,IAAA,SAAS,EAAC,OAAf;AAAA,4BACI,QAAC,MAAD;AACE,MAAA,GAAG,EAAElB,SADP;AAEE,MAAA,KAAK,EAAE;AACV4B,QAAAA,KAAK,EAAE,MADG;AAEVC,QAAAA,MAAM,EAAE;AAFE;AAFT;AAAA;AAAA;AAAA;AAAA,YADJ,eAQI;AACE,MAAA,GAAG,EAAE5B,SADP;AAEE,MAAA,KAAK,EAAE;AACLgC,QAAAA,UAAU,EAAE,MADP;AAELC,QAAAA,WAAW,EAAE,MAFR;AAGLC,QAAAA,IAAI,EAAE,CAHD;AAILC,QAAAA,KAAK,EAAE,CAJF;AAKLC,QAAAA,SAAS,EAAE,QALN;AAMLC,QAAAA,MAAM,EAAE,CANH;AAOLV,QAAAA,KAAK,EAAE,GAPF;AAQLC,QAAAA,MAAM,EAAE;AARH;AAFT;AAAA;AAAA;AAAA;AAAA,YARJ;AAAA;AAAA;AAAA;AAAA;AAAA,UADD;AAwBA;;GA7EQ/B,K;;KAAAA,K;AA+ET,eAAeA,KAAf","sourcesContent":["import React, { useRef } from 'react'\nimport * as tf from '@tensorflow/tfjs'\nimport * as handpose from '@tensorflow-models/handpose'\nimport Webcam from 'react-webcam'\nimport './Model.css'\n\nfunction Model(props) {\n\tconst webcamRef = useRef(null);\n\tconst canvasRef = useRef(null);\n\n\tconst drawHand = (predictions, ctx) => {\n\t\tif (predictions.length > 0) {\n\t\t\tpredictions.forEach(prediction => {\n\t\t\t\tconst landmarks = prediction.landmarks;\n\t\t\t\tfor (let i = 0; i < landmarks.length; i ++) {\n\t\t\t\t\tconst x = landmarks[i][0];\n\t\t\t\t\tconst y = landmarks[i][1];\n\n\t\t\t\t\tctx.beginPath();\n\t\t\t\t\tctx.arc(x, y, 5, 0, 3 * Math.PI);\n\t\t\t\t\tctx.fillStyle = \"indigo\";\n\t\t\t\t\tctx.fill();\n\t\t\t\t}\n\t\t\t})\n\t\t}\n\t}\n\n\tconst runHandpose = async () => {\n\t\tconst net = await handpose.load();\n\n\t\tsetInterval(() => {\n\t\t\tdetect(net);\n\t\t}, 100)\n\t}\n\n  const detect = async (net) => {\n    if (\n      typeof webcamRef.current !== \"undefined\" &&\n      webcamRef.current !== null &&\n      webcamRef.current.video.readyState === 4\n    ) {\n      const video = webcamRef.current.video;\n      const videoWidth = webcamRef.current.video.videoWidth;\n      const videoHeight = webcamRef.current.video.videoHeight;\n\n      webcamRef.current.video.width = videoWidth;\n      webcamRef.current.video.height = videoHeight;\n\n      canvasRef.current.width = videoWidth;\n      canvasRef.current.height = videoHeight;\n\n      const hand = await net.estimateHands(video);\n\t\t\tconst ctx = canvasRef.current.getContext(\"2d\");\n\t\t\tdrawHand(hand, ctx);\n    }\n  };\n\n  runHandpose();\n\n\treturn (\n\t\t<div className=\"model\">\n      <Webcam\n        ref={webcamRef}\n        style={{\n\t\t\t\t\twidth: \"100%\",\n\t\t\t\t\theight: \"100%\",\n        }}\n      />\n      <canvas\n        ref={canvasRef}\n        style={{\n          marginLeft: \"auto\",\n          marginRight: \"auto\",\n          left: 0,\n          right: 0,\n          textAlign: \"center\",\n          zindex: 9,\n          width: 640,\n          height: 480,\n        }}\n      />\n\t\t</div>\n\t)\n}\n\nexport default Model"]},"metadata":{},"sourceType":"module"}